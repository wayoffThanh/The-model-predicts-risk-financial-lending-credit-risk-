{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-14T07:56:52.720148Z",
     "iopub.status.busy": "2025-05-14T07:56:52.719995Z",
     "iopub.status.idle": "2025-05-14T07:57:07.090335Z",
     "shell.execute_reply": "2025-05-14T07:57:07.089776Z",
     "shell.execute_reply.started": "2025-05-14T07:56:52.720133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_auc_score, average_precision_score, matthews_corrcoef, log_loss\n",
    ")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T08:12:38.267303Z",
     "iopub.status.busy": "2025-05-14T08:12:38.266468Z",
     "iopub.status.idle": "2025-05-14T08:14:19.071650Z",
     "shell.execute_reply": "2025-05-14T08:14:19.070818Z",
     "shell.execute_reply.started": "2025-05-14T08:12:38.267274Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/1833196882.py:4: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "    adapter=KaggleDatasetAdapter.PANDAS,\n",
    "    handle=\"ducthanhvu/doan-2-cuoi-cung\",\n",
    "    path=\"Data doan cuoi cung.xlsx\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T08:15:35.384464Z",
     "iopub.status.busy": "2025-05-14T08:15:35.383974Z",
     "iopub.status.idle": "2025-05-14T08:15:36.651083Z",
     "shell.execute_reply": "2025-05-14T08:15:36.650286Z",
     "shell.execute_reply.started": "2025-05-14T08:15:35.384436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"cbm_feature_1\"] = df[\"wallet_usage_frequency\"] * df[\"bank_avg_balance\"]\n",
    "df[\"cbm_feature_2\"] = df[\"risk_score_raw\"] * df[\"loan_count_score\"]\n",
    "\n",
    "# Expand and enrich text feature\n",
    "loan_purpose_templates = [\n",
    "    \"I need this loan to pay for my {purpose}.\",\n",
    "    \"This funding will help cover my {purpose}.\",\n",
    "    \"The loan is intended for {purpose}.\",\n",
    "    \"I am applying to cover expenses related to {purpose}.\",\n",
    "    \"These funds will support my {purpose} needs.\",\n",
    "    \"The money will be used primarily for {purpose}.\"\n",
    "]\n",
    "loan_purposes = [\n",
    "    \"home renovation\", \"medical expenses\", \"debt consolidation\", \"starting a small business\",\n",
    "    \"education tuition fees\", \"vehicle repairs\", \"wedding expenses\", \"family emergency\",\n",
    "    \"travel plans\", \"childcare costs\", \"unforeseen bills\", \"buying new equipment\",\n",
    "    \"moving to a new home\", \"paying off credit card debt\", \"supporting a relative\"\n",
    "]\n",
    "df[\"loan_purpose_text\"] = [\n",
    "    random.choice(loan_purpose_templates).format(purpose=random.choice(loan_purposes))\n",
    "    for _ in range(len(df))\n",
    "]\n",
    "\n",
    "# Encode features and prepare inputs\n",
    "label_col = \"default\"\n",
    "text_col = \"loan_purpose_text\"\n",
    "selected_features = [\n",
    "    \"age\", \"gender\", \"marital_status\", \"residential_area\", \"monthly_income\",\n",
    "    \"estimated_monthly_expense\", \"employment_status\", \"job_type\",\n",
    "    \"total_outstanding_debt\", \"number_of_current_loans\", \"total_late_payments\",\n",
    "    \"num_loans_from_app\", \"num_late_payments_in_app\", \"has_bank_account_linked\",\n",
    "    \"bank_avg_balance\", \"has_e_wallet_linked\", \"wallet_usage_frequency\",\n",
    "    \"cbm_feature_1\", \"cbm_feature_2\"\n",
    "]\n",
    "X_tabular = df[selected_features].copy()\n",
    "X_text = df[text_col].astype(str)\n",
    "y = df[label_col]\n",
    "\n",
    "categorical_cols = X_tabular.select_dtypes(include=\"object\").columns.tolist()\n",
    "encoder = ce.OrdinalEncoder(cols=categorical_cols)\n",
    "X_encoded = encoder.fit_transform(X_tabular)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T08:15:55.441706Z",
     "iopub.status.busy": "2025-05-14T08:15:55.441394Z",
     "iopub.status.idle": "2025-05-14T08:16:16.128550Z",
     "shell.execute_reply": "2025-05-14T08:16:16.127895Z",
     "shell.execute_reply.started": "2025-05-14T08:15:55.441686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8000dedc978e48ac8a4fb00b544ee3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4280021c352488abf09ef579a7efe19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "encoded_text = tokenizer(\n",
    "    X_text.tolist(), padding=True, truncation=True, max_length=32, return_tensors=\"pt\"\n",
    ")\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_tab_train, X_tab_test, ids_train, ids_test, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "    torch.tensor(X_scaled, dtype=torch.float32), encoded_text[\"input_ids\"], y_tensor,\n",
    "    encoded_text[\"attention_mask\"], test_size=0.2, random_state=42\n",
    ")\n",
    "train_dataset = TensorDataset(X_tab_train, ids_train, mask_train, y_train)\n",
    "test_dataset = TensorDataset(X_tab_test, ids_test, mask_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.731Z",
     "iopub.execute_input": "2025-05-14T08:18:36.973006Z",
     "iopub.status.busy": "2025-05-14T08:18:36.972151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 08:18:43.017917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747210723.215048      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747210723.279389      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a2e17a48f44edb870ee946a29c5380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb8e47a069f4eb181b41fc984ad483d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.7005 | Test Loss: 0.7004 | AUC: 0.5212\n",
      "Epoch 02 | Train Loss: 0.6999 | Test Loss: 0.7000 | AUC: 0.5253\n",
      "Epoch 03 | Train Loss: 0.6995 | Test Loss: 0.6995 | AUC: 0.5303\n",
      "Epoch 04 | Train Loss: 0.6989 | Test Loss: 0.6997 | AUC: 0.5336\n",
      "Epoch 05 | Train Loss: 0.6984 | Test Loss: 0.6987 | AUC: 0.5366\n",
      "Epoch 06 | Train Loss: 0.6975 | Test Loss: 0.6985 | AUC: 0.5389\n",
      "Epoch 07 | Train Loss: 0.6961 | Test Loss: 0.6968 | AUC: 0.5467\n",
      "Epoch 08 | Train Loss: 0.6945 | Test Loss: 0.6950 | AUC: 0.5554\n",
      "Epoch 09 | Train Loss: 0.6921 | Test Loss: 0.6945 | AUC: 0.5614\n",
      "Epoch 10 | Train Loss: 0.6886 | Test Loss: 0.6895 | AUC: 0.5721\n",
      "Epoch 11 | Train Loss: 0.6845 | Test Loss: 0.6868 | AUC: 0.5778\n",
      "Epoch 12 | Train Loss: 0.6798 | Test Loss: 0.6805 | AUC: 0.5894\n",
      "Epoch 13 | Train Loss: 0.6742 | Test Loss: 0.6820 | AUC: 0.5930\n",
      "Epoch 14 | Train Loss: 0.6681 | Test Loss: 0.6714 | AUC: 0.6093\n",
      "Epoch 15 | Train Loss: 0.6616 | Test Loss: 0.6632 | AUC: 0.6273\n",
      "Epoch 16 | Train Loss: 0.6552 | Test Loss: 0.6572 | AUC: 0.6363\n",
      "Epoch 17 | Train Loss: 0.6487 | Test Loss: 0.6540 | AUC: 0.6414\n",
      "Epoch 18 | Train Loss: 0.6424 | Test Loss: 0.6443 | AUC: 0.6592\n",
      "Epoch 19 | Train Loss: 0.6355 | Test Loss: 0.6391 | AUC: 0.6655\n",
      "Epoch 20 | Train Loss: 0.6293 | Test Loss: 0.6340 | AUC: 0.6749\n",
      "Epoch 21 | Train Loss: 0.6221 | Test Loss: 0.6272 | AUC: 0.6841\n",
      "Epoch 22 | Train Loss: 0.6168 | Test Loss: 0.6203 | AUC: 0.6934\n",
      "Epoch 23 | Train Loss: 0.6094 | Test Loss: 0.6162 | AUC: 0.6996\n",
      "Epoch 24 | Train Loss: 0.6043 | Test Loss: 0.6058 | AUC: 0.7118\n",
      "Epoch 25 | Train Loss: 0.5975 | Test Loss: 0.5992 | AUC: 0.7223\n",
      "Epoch 26 | Train Loss: 0.5913 | Test Loss: 0.5917 | AUC: 0.7294\n",
      "Epoch 27 | Train Loss: 0.5844 | Test Loss: 0.5858 | AUC: 0.7376\n",
      "Epoch 28 | Train Loss: 0.5785 | Test Loss: 0.5756 | AUC: 0.7490\n",
      "Epoch 29 | Train Loss: 0.5724 | Test Loss: 0.5752 | AUC: 0.7514\n",
      "Epoch 30 | Train Loss: 0.5657 | Test Loss: 0.5672 | AUC: 0.7582\n",
      "Epoch 31 | Train Loss: 0.5589 | Test Loss: 0.5602 | AUC: 0.7658\n",
      "Epoch 32 | Train Loss: 0.5531 | Test Loss: 0.5506 | AUC: 0.7751\n",
      "Epoch 33 | Train Loss: 0.5469 | Test Loss: 0.5450 | AUC: 0.7804\n",
      "Epoch 34 | Train Loss: 0.5395 | Test Loss: 0.5393 | AUC: 0.7876\n",
      "Epoch 35 | Train Loss: 0.5336 | Test Loss: 0.5304 | AUC: 0.7950\n",
      "Epoch 36 | Train Loss: 0.5278 | Test Loss: 0.5232 | AUC: 0.8033\n",
      "Epoch 37 | Train Loss: 0.5224 | Test Loss: 0.5200 | AUC: 0.8058\n",
      "Epoch 38 | Train Loss: 0.5159 | Test Loss: 0.5094 | AUC: 0.8155\n",
      "Epoch 39 | Train Loss: 0.5099 | Test Loss: 0.5027 | AUC: 0.8205\n",
      "Epoch 40 | Train Loss: 0.5038 | Test Loss: 0.5006 | AUC: 0.8234\n",
      "Epoch 41 | Train Loss: 0.4971 | Test Loss: 0.4905 | AUC: 0.8303\n",
      "Epoch 42 | Train Loss: 0.4925 | Test Loss: 0.4855 | AUC: 0.8349\n",
      "Epoch 43 | Train Loss: 0.4865 | Test Loss: 0.4787 | AUC: 0.8402\n",
      "Epoch 44 | Train Loss: 0.4804 | Test Loss: 0.4757 | AUC: 0.8423\n",
      "Epoch 45 | Train Loss: 0.4769 | Test Loss: 0.4699 | AUC: 0.8476\n",
      "Epoch 46 | Train Loss: 0.4704 | Test Loss: 0.4598 | AUC: 0.8556\n",
      "Epoch 47 | Train Loss: 0.4653 | Test Loss: 0.4561 | AUC: 0.8586\n",
      "Epoch 48 | Train Loss: 0.4602 | Test Loss: 0.4506 | AUC: 0.8622\n",
      "Epoch 49 | Train Loss: 0.4556 | Test Loss: 0.4428 | AUC: 0.8674\n",
      "Epoch 50 | Train Loss: 0.4496 | Test Loss: 0.4360 | AUC: 0.8714\n",
      "Epoch 51 | Train Loss: 0.4446 | Test Loss: 0.4348 | AUC: 0.8729\n",
      "Epoch 52 | Train Loss: 0.4408 | Test Loss: 0.4272 | AUC: 0.8787\n",
      "Epoch 53 | Train Loss: 0.4358 | Test Loss: 0.4220 | AUC: 0.8822\n",
      "Epoch 54 | Train Loss: 0.4305 | Test Loss: 0.4171 | AUC: 0.8843\n",
      "Epoch 55 | Train Loss: 0.4265 | Test Loss: 0.4107 | AUC: 0.8894\n",
      "Epoch 56 | Train Loss: 0.4224 | Test Loss: 0.4063 | AUC: 0.8914\n",
      "Epoch 57 | Train Loss: 0.4179 | Test Loss: 0.4019 | AUC: 0.8941\n",
      "Epoch 58 | Train Loss: 0.4134 | Test Loss: 0.3939 | AUC: 0.8989\n",
      "Epoch 59 | Train Loss: 0.4088 | Test Loss: 0.3904 | AUC: 0.9012\n",
      "Epoch 60 | Train Loss: 0.4046 | Test Loss: 0.3879 | AUC: 0.9032\n",
      "Epoch 61 | Train Loss: 0.3991 | Test Loss: 0.3825 | AUC: 0.9056\n",
      "Epoch 62 | Train Loss: 0.3955 | Test Loss: 0.3720 | AUC: 0.9109\n",
      "Epoch 63 | Train Loss: 0.3917 | Test Loss: 0.3729 | AUC: 0.9125\n",
      "Epoch 64 | Train Loss: 0.3884 | Test Loss: 0.3726 | AUC: 0.9123\n",
      "Epoch 65 | Train Loss: 0.3845 | Test Loss: 0.3655 | AUC: 0.9161\n",
      "Epoch 66 | Train Loss: 0.3793 | Test Loss: 0.3590 | AUC: 0.9187\n",
      "Epoch 67 | Train Loss: 0.3762 | Test Loss: 0.3571 | AUC: 0.9198\n",
      "Epoch 68 | Train Loss: 0.3724 | Test Loss: 0.3515 | AUC: 0.9232\n",
      "Epoch 69 | Train Loss: 0.3690 | Test Loss: 0.3466 | AUC: 0.9254\n",
      "Epoch 70 | Train Loss: 0.3654 | Test Loss: 0.3433 | AUC: 0.9270\n",
      "Epoch 71 | Train Loss: 0.3615 | Test Loss: 0.3377 | AUC: 0.9299\n",
      "Epoch 72 | Train Loss: 0.3581 | Test Loss: 0.3316 | AUC: 0.9317\n",
      "Epoch 73 | Train Loss: 0.3533 | Test Loss: 0.3340 | AUC: 0.9309\n",
      "Epoch 74 | Train Loss: 0.3502 | Test Loss: 0.3302 | AUC: 0.9331\n",
      "Epoch 75 | Train Loss: 0.3466 | Test Loss: 0.3241 | AUC: 0.9357\n",
      "Epoch 76 | Train Loss: 0.3451 | Test Loss: 0.3231 | AUC: 0.9358\n",
      "Epoch 77 | Train Loss: 0.3413 | Test Loss: 0.3151 | AUC: 0.9395\n",
      "Epoch 78 | Train Loss: 0.3388 | Test Loss: 0.3153 | AUC: 0.9402\n",
      "Epoch 79 | Train Loss: 0.3341 | Test Loss: 0.3112 | AUC: 0.9406\n",
      "Epoch 80 | Train Loss: 0.3311 | Test Loss: 0.3074 | AUC: 0.9435\n"
     ]
    }
   ],
   "source": [
    "class TabFinBERT_CBModel(nn.Module):\n",
    "    def __init__(self, tab_input_dim, text_model_name=\"yiyanghkust/finbert-tone\", d_model=128, n_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.tabular_proj = nn.Linear(tab_input_dim, d_model)\n",
    "        self.tab_transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dropout=dropout, batch_first=True),\n",
    "            num_layers=2)\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "        self.text_proj = nn.Linear(self.text_encoder.config.hidden_size, d_model)\n",
    "        self.cbm_proj = nn.Sequential(nn.Linear(2, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(d_model * 3, 64), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1))\n",
    "\n",
    "    def forward(self, x_tab, input_ids, attention_mask, cbm):\n",
    "        tab_encoded = self.tabular_proj(x_tab)\n",
    "        tab_out = self.tab_transformer(tab_encoded.unsqueeze(1)).squeeze(1)\n",
    "        text_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = text_out.pooler_output\n",
    "        text_out = self.text_proj(pooled)\n",
    "        cbm_out = self.cbm_proj(cbm)\n",
    "        combined = torch.cat([tab_out, text_out, cbm_out], dim=1)\n",
    "        return self.final(combined)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TabFinBERT_CBModel(tab_input_dim=X_tab_train.shape[1]).to(device)\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0, 1]), y=df[label_col])\n",
    "pos_weight = torch.tensor([class_weights[1] / class_weights[0]]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=4, factor=0.5, verbose=True)\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "best_loss, patience, counter = float('inf'), 8, 0\n",
    "\n",
    "for epoch in range(1, 151):\n",
    "    model.train(); total_train_loss = 0\n",
    "    for x_tab, ids, mask, yb in train_loader:\n",
    "        x_tab, ids, mask, yb = x_tab.to(device), ids.to(device), mask.to(device), yb.to(device)\n",
    "        cbm = x_tab[:, -2:]\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_tab, ids, mask, cbm)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward(); optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    train_losses.append(total_train_loss / len(train_loader))\n",
    "\n",
    "    \n",
    "    model.eval(); total_test_loss, all_preds, all_labels = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x_tab, ids, mask, yb in test_loader:\n",
    "            x_tab, ids, mask, yb = x_tab.to(device), ids.to(device), mask.to(device), yb.to(device)\n",
    "            cbm = x_tab[:, -2:]\n",
    "            logits = model(x_tab, ids, mask, cbm)\n",
    "            loss = criterion(logits, yb)\n",
    "            total_test_loss += loss.item()\n",
    "            preds = torch.sigmoid(logits)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "    avg_test_loss = total_test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_losses[-1]:.4f} | Test Loss: {avg_test_loss:.4f} | AUC: {auc:.4f}\")\n",
    "    scheduler.step(avg_test_loss)\n",
    "\n",
    "    if avg_test_loss < best_loss:\n",
    "        best_loss, best_model_state, counter = avg_test_loss, model.state_dict(), 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\"); break\n",
    "\n",
    "if best_model_state:\n",
    "    model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T19:09:09.654330Z",
     "iopub.status.busy": "2025-05-14T19:09:09.654128Z",
     "iopub.status.idle": "2025-05-14T19:09:09.731838Z",
     "shell.execute_reply": "2025-05-14T19:09:09.730848Z",
     "shell.execute_reply.started": "2025-05-14T19:09:09.654311Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/2132259178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/kaggle/working/model_final.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"/kaggle/working/model_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "class SimpleTabModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model.tabular_proj\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "shap_model = SimpleTabModel(model).to(\"cpu\")\n",
    "explainer = shap.Explainer(shap_model, torch.tensor(X_scaled[:1000], dtype=torch.float32))\n",
    "shap_values = explainer(torch.tensor(X_scaled[:1000], dtype=torch.float32))\n",
    "shap.summary_plot(shap_values.values, features=X_encoded.iloc[:1000], feature_names=X_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[0],\n",
    "    shap_values=shap_values.values[0],\n",
    "    features=X_encoded.iloc[0],\n",
    "    feature_names=X_encoded.columns.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values.mean(0), max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_true, y_pred_binary)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Default\", \"Default\"], yticklabels=[\"No Default\", \"Default\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix (Seaborn)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-14T19:07:33.738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=10)\n",
    "plt.plot(prob_pred, prob_true, marker='o')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"True probability in bin\")\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12296092,
     "datasetId": 7414560,
     "sourceId": 11806237,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
